{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Environment import Environment\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1, c2, c3, arm, last_l, last_r = list(range(0, 6))\n",
    "empty, red, blue, green = list(range(0, 4))\n",
    "actions = [\"pickL\", \"pickM\", \"pickR\", \"putL\", \"putR\"]\n",
    "\n",
    "\n",
    "def updateQ(Q, s, a, r, sn, gamma, alpha=0.05):\n",
    "    old_value = Q[s[c1], s[c2], s[c3], s[arm], s[last_l], s[last_r], actions.index(a)]\n",
    "    optimal_fut_value = np.max(Q[sn[c1], sn[c2], sn[c3], sn[arm], sn[last_l], sn[last_r], :])\n",
    "    update = (1.0 - alpha) * old_value + alpha * (r + gamma * optimal_fut_value)\n",
    "    Q[s[c1], s[c2], s[c3], s[arm], s[last_l], s[last_r], actions.index(a)] = update\n",
    "\n",
    "def train(iterations=10000, traj_len=100, alpha=1.0, alpha_decay=0.999,  \\\n",
    "          alpha_min=0.05, gamma=0.95, exp_decay=0.999, exp_min=0.5, stats=False):\n",
    "    env = Environment()\n",
    "    gamma = 0.95\n",
    "    Q = np.ones((4, 4, 4, 4, 4, 4, 5))\n",
    "    exp = 1.0\n",
    "    for it in tqdm(range(iterations)):\n",
    "        env.reset()\n",
    "        s = env.get_current_state()\n",
    "        for step in range(traj_len):\n",
    "            if np.random.uniform(0, 1) <= max(exp, exp_min):\n",
    "                a = actions[np.random.randint(0, 5)]\n",
    "            else:\n",
    "                a = actions[np.argmax(Q[s[c1], s[c2], s[c3], s[arm], s[last_l], s[last_r], :])]\n",
    "            r = env.get_reward(s, a)\n",
    "            sn = env.execute_action(a)\n",
    "            updateQ(Q, s, a, r, sn, gamma, max(alpha, alpha_min))\n",
    "            s = sn\n",
    "            alpha = alpha * alpha_decay\n",
    "            exp = exp * exp_decay\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:33<00:00, 468.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 622.34556198  619.31449211  665.17898279  625.78784163  622.00692976]\n",
      " [   1.            1.            1.            1.            1.        ]\n",
      " [   1.            1.            1.            1.            1.        ]\n",
      " [   1.            1.            1.            1.            1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Q = train(iterations=100000)\n",
    "print(Q[1, 2, 3, :, 2, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrajectory(Q, maxLength=200):\n",
    "    env = Environment()\n",
    "    traj_s = []\n",
    "    traj_a = []\n",
    "    traj_r = []\n",
    "    s = env.get_current_state()\n",
    "    for i in range(maxLength):\n",
    "        a = actions[np.argmax(Q[s[c1], s[c2], s[c3], s[arm], s[last_l], s[last_r], :])]\n",
    "        traj_s.append(s)\n",
    "        traj_a.append(a)\n",
    "        traj_r.append(env.get_reward(s, a))\n",
    "        s = env.execute_action(a)\n",
    "    return traj_s, traj_a, traj_r\n",
    "\n",
    "def getTrajectories(Q, M=100, maxLength=50):\n",
    "    trajs = []\n",
    "    for i in range(M):\n",
    "        trajs.append([getTrajectory(Q, maxLength)])\n",
    "    return np.array(trajs).reshape(M,3,maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(Q[1, 2, 3, :, 0, 0, :])\n",
    "# print(Q[1, 2, 3, :, 2, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rsum = 0\n",
    "# counter = 0\n",
    "# alog = []\n",
    "# for i in range(0, 10000):\n",
    "#     counter += 1\n",
    "#     s = np.copy(s)\n",
    "#     a = actions[np.argmax(Q[s[c1], s[c2], s[c3], s[arm], s[last_l], s[last_r], :])]\n",
    "#     alog.append(actions.index(a))\n",
    "#     r = env.get_reward(s, a)\n",
    "#     rsum += r\n",
    "#     print((str(s) + ' | ' + a + ' | ' + str(r) + ' | {:.2f}'.format(rsum/counter)), end='\\r')\n",
    "#     s = env.execute_action(a)\n",
    "#     # time.sleep(0.8)\n",
    "    \n",
    "# plt.hist(alog, bins=5, normed=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "# initial state distribution\n",
    "D = env.get_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
      "\n",
      "[[0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def state_action_to_fs(s, a):\n",
    "    f = []\n",
    "    for sv in range(len(s)):\n",
    "        sv_one_hot = [0] * 4\n",
    "        sv_one_hot[s[sv]] = 1\n",
    "        f += sv_one_hot\n",
    "    a_one_hot = [0] * 5\n",
    "    a_one_hot[actions.index(a)] = 1\n",
    "    f += a_one_hot\n",
    "    return np.array(f)\n",
    "\n",
    "def traj_to_fss(traj):\n",
    "    res = []\n",
    "    for i in range(traj.shape[1]):\n",
    "        s = traj[0,i]\n",
    "        a = traj[1,i]\n",
    "        res.append(state_action_to_fs(s, a))\n",
    "    return np.array(res)\n",
    "\n",
    "def trajs_to_fss(trajs):\n",
    "    res = []\n",
    "    for i in range(len(trajs)):\n",
    "        res.append(traj_to_fss(trajs[i]))\n",
    "    return np.array(res)\n",
    "    \n",
    "trajs = getTrajectories(Q, M=500)\n",
    "print(state_action_to_fs(trajs[0,0,0], trajs[0,1,0]))\n",
    "print('')\n",
    "print(traj_to_fss(trajs[0,:,:])[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.    1.    0.    0.    0.48  0.24  0.28  0.    0.    1.    0.    0.5\n",
      "  0.22  0.14  0.14  0.    0.72  0.16  0.12  0.    0.    0.48  0.52  0.\n",
      "  0.48  0.02  0.28  0.22]\n",
      "()\n",
      "[[ 0.    0.    1.    0.    0.    0.48  0.24  0.28  0.    0.    1.    0.\n",
      "   0.5   0.22  0.14  0.14  0.    0.72  0.16  0.12  0.    0.    0.48  0.52\n",
      "   0.    0.48  0.02  0.28  0.22]\n",
      " [ 0.    0.    1.    0.    0.    0.44  0.14  0.42  0.    0.04  0.96  0.\n",
      "   0.5   0.2   0.1   0.2   0.    0.76  0.08  0.16  0.    0.    0.12  0.88\n",
      "   0.    0.46  0.04  0.28  0.22]]\n"
     ]
    }
   ],
   "source": [
    "def f_zeta(traj):\n",
    "    res = np.zeros(29)\n",
    "    for i in range(traj.shape[1]):\n",
    "        s = traj[0,i]\n",
    "        a = traj[1,i]\n",
    "        res += state_action_to_fs(s, a)\n",
    "    res /= traj.shape[1]\n",
    "    return res\n",
    "\n",
    "def f_zetas(trajs):\n",
    "    res = []\n",
    "    for i in range(trajs.shape[0]):\n",
    "        traj = trajs[i,:,:]\n",
    "        res.append(f_zeta(traj))\n",
    "    res = np.array(res)\n",
    "    return res\n",
    "\n",
    "print(f_zeta(trajs[0,:,:]))\n",
    "print()\n",
    "print(f_zetas(trajs))[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       0.03056  0.94992  0.01952  0.       0.40064  0.30908  0.29028\n",
      "  0.       0.05888  0.89432  0.0468   0.5      0.16312  0.16924  0.16764\n",
      "  0.       0.67656  0.09104  0.2324   0.       0.0024   0.4764   0.5212\n",
      "  0.01128  0.43144  0.05728  0.25596  0.24404]\n"
     ]
    }
   ],
   "source": [
    "def expexted_emp_feat_count(trajs):\n",
    "    res = np.zeros(29)\n",
    "    for i in range(trajs.shape[0]):\n",
    "        traj = trajs[i,:,:]\n",
    "        res += f_zeta(traj)\n",
    "    res /= trajs.shape[0]\n",
    "    return res\n",
    "\n",
    "print(expexted_emp_feat_count(trajs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rpred(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Rpred, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(29, 200)\n",
    "        self.lin2 = torch.nn.Linear(200, 200)\n",
    "        self.lin3 = torch.nn.Linear(200, 1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x).clamp(min=0)\n",
    "        out = self.lin2(out).clamp(min=0)\n",
    "        out = self.tanh(self.lin3(out))\n",
    "        return out\n",
    "    \n",
    "rpred = Rpred()\n",
    "optimizer = torch.optim.Adagrad(rpred.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.23168182373\n",
      "6.21478939056\n",
      "6.21471595764\n",
      "6.21466732025\n",
      "6.21465778351\n",
      "6.21464061737\n"
     ]
    }
   ],
   "source": [
    "fss_trajs = trajs_to_fss(trajs)\n",
    "# print(fss_trajs.shape)\n",
    "fss_trajs = Variable(torch.from_numpy(fss_trajs)).float()\n",
    "\n",
    "for i in range(0, 250):\n",
    "    rpreds = rpred(fss_trajs).view(fss_trajs.data.shape[0],fss_trajs.data.shape[1])\n",
    "    # print(rpreds.data[0,:5])\n",
    "\n",
    "    R_of_zeta = torch.sum(rpreds, dim=1)\n",
    "\n",
    "    objective = (1.0 / fss_trajs.data.shape[0]) * torch.sum(R_of_zeta) - torch.log(torch.sum(torch.exp(R_of_zeta)))\n",
    "    loss = -objective\n",
    "    if i % 49 == 0:\n",
    "        print(loss.data[0])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 50, 29])\n",
      "\n",
      " 0.1496\n",
      " 0.7039\n",
      " 0.2371\n",
      " 0.5003\n",
      " 0.2850\n",
      " 0.4999\n",
      " 0.1589\n",
      " 0.4418\n",
      " 0.2356\n",
      " 0.6477\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "[array([2, 2, 2, 0, 3, 2]) array([2, 3, 2, 2, 3, 2])\n",
      " array([2, 3, 2, 0, 2, 2]) array([2, 2, 2, 3, 2, 2])\n",
      " array([2, 2, 2, 0, 2, 3]) array([2, 1, 2, 2, 2, 3])\n",
      " array([2, 1, 2, 0, 2, 2]) array([2, 2, 2, 1, 2, 2])\n",
      " array([2, 2, 2, 0, 1, 2]) array([2, 3, 2, 2, 1, 2])]\n",
      "['pick2' 'putL' 'pick2' 'putR' 'pick2' 'putR' 'pick2' 'putL' 'pick2' 'putR']\n",
      "[0 30 0 60 0 40 0 110 0 40]\n"
     ]
    }
   ],
   "source": [
    "print(fss_trajs.data.shape)\n",
    "res = rpred(fss_trajs)\n",
    "print(((res-torch.min(res))/(torch.max(res)-torch.min(res))).data[0, 0:10,0])\n",
    "print(trajs[0,0,0:10])\n",
    "print(trajs[0,1,0:10])\n",
    "print(trajs[0,2,0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n",
      "(500, 3, 50)\n",
      "[0 30 0 60 0 40 0 110 0 40]\n",
      "[0.14955051243305206 0.7038653492927551 0.23709285259246826\n",
      " 0.5003016591072083 0.28498154878616333 0.49986353516578674\n",
      " 0.1589118391275406 0.4418087899684906 0.23557858169078827\n",
      " 0.6476856470108032]\n"
     ]
    }
   ],
   "source": [
    "print(res.data.numpy().reshape(500, 50).shape)\n",
    "print(trajs.shape)\n",
    "print(trajs[0,2,0:10])\n",
    "trajs[:,2,:] = ((res-torch.min(res))/(torch.max(res)-torch.min(res))).data.numpy().reshape(500, 50)\n",
    "print(trajs[0,2,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainFromRpred(rpred, iterations=10000, traj_len=100, alpha=1.0, alpha_decay=0.999,  \\\n",
    "          alpha_min=0.01, gamma=0.95, exp_decay=0.999, exp_min=0.5):\n",
    "    env = Environment()\n",
    "    gamma = 0.95\n",
    "    Q = np.ones((4, 4, 4, 4, 4, 4, 5))\n",
    "    exp = 1.0\n",
    "    for it in tqdm(range(iterations)):\n",
    "        env.reset()\n",
    "        s = env.get_current_state()\n",
    "        for step in range(traj_len):\n",
    "            if np.random.uniform(0, 1) <= max(exp, exp_min):\n",
    "                a = actions[np.random.randint(0, 5)]\n",
    "            else:\n",
    "                a = actions[np.argmax(Q[s[c1], s[c2], s[c3], s[arm], s[last_l], s[last_r], :])]\n",
    "            f = state_action_to_fs(s, a)\n",
    "            r = rpred(Variable(torch.from_numpy(f)).float())\n",
    "            sn = env.execute_action(a)\n",
    "            updateQ(Q, s, a, r, sn, gamma, max(alpha, alpha_min))\n",
    "            s = sn\n",
    "            alpha = alpha * alpha_decay\n",
    "            exp = exp * exp_decay\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 587.59561124  559.69719939  589.26943229  567.06267407  565.82049886]\n",
      " [ 610.60765574  613.05403136  610.41672609  642.65827027  567.0862429 ]\n",
      " [ 547.2628839   548.92877154  539.04725131  538.25218967  597.47123372]\n",
      " [ 475.13891219  491.39377715  476.11314133  544.31853382  369.36045139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ab4de6824b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mQirl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainFromRpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQirl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e6c31e2f4af6>\u001b[0m in \u001b[0;36mtrainFromRpred\u001b[0;34m(rpred, iterations, traj_len, alpha, alpha_decay, alpha_min, gamma, exp_decay, exp_min)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0msn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mupdateQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5e8fef99165f>\u001b[0m in \u001b[0;36mupdateQ\u001b[0;34m(Q, s, a, r, sn, gamma, alpha)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimal_fut_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mold_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moptimal_fut_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0malpha_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "print(Q[1, 2, 3, :, 2, 1, :])\n",
    "Qirl = trainFromRpred(rpred, iterations=100000)\n",
    "print(Qirl[1, 2, 3, :, 2, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0772\n",
      "31.7352\n"
     ]
    }
   ],
   "source": [
    "trajs = getTrajectories(Q, M=500)\n",
    "trajsirl = getTrajectories(Q, M=500)\n",
    "print(np.mean(trajs[:,2,:]))\n",
    "print(np.mean(trajsirl[:,2,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def freq_sPrime_after(trajs, s, a, sPrime):\n",
    "#     if a.startswith(\"pick\"):\n",
    "#         return 1.0/3\n",
    "#     else:\n",
    "#         return 1.0\n",
    "#     # TODO: use commented code and populate in-memory transition matrix\n",
    "# #     successors = []\n",
    "# #     for traj in trajs:\n",
    "# #         for i in range(traj.shape[1] - 1):\n",
    "# #             if np.array_equal(traj[0,i], s) and traj[1,i] == a:\n",
    "# #                 successors.append(traj[0,i+1])\n",
    "# #     successors = np.array(successors)\n",
    "# #     count_sPrime = len(np.where((successors == sPrime).all(axis=1))[0])\n",
    "# #     freq = float(count_sPrime) / len(successors)\n",
    "# #     return freq\n",
    "    \n",
    "# r = []\n",
    "# for i in range(trajs.shape[2]-1):\n",
    "#     r.append(np.log(freq_sPrime_after(trajs, trajs[0, 0, i], trajs[0, 1, i], trajs[0, 0, i+1])))\n",
    "# r = np.array(r)\n",
    "# np.sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 475.13891219  491.39377715  476.11314133  544.31853382  369.36045139]\n",
      "369.360451392\n",
      "544.318533819\n",
      "0.678574085657\n"
     ]
    }
   ],
   "source": [
    "s = [1, 2, 3, 3, 2, 1]\n",
    "exp_val = Q[s[0], s[1], s[2], s[3], s[4], s[5], actions.index(\"putR\")]\n",
    "possible_vals = Q[s[0], s[1], s[2], s[3], s[4], s[5], :]\n",
    "best_val = np.max(possible_vals)\n",
    "quality = exp_val / best_val\n",
    "print(possible_vals)\n",
    "print(exp_val)\n",
    "print(best_val)\n",
    "print(quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
